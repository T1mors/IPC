{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_X_digits = train_labels\n",
    "vec_y = np.zeros((1, mat_X_digits.shape[1])) \n",
    "digit_B_mask = mat_X_digits[0,:] == digit_B\n",
    "digit_B_mask = np.expand_dims(digit_B_mask,axis=0)  #(1,N)\n",
    "vec_y[digit_B_mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_X = matrix2vector(train_images)\n",
    "mat_X_digits = train_labels\n",
    "vec_L = []\n",
    "vec_y = map_digit_to_vec_y(mat_X_digits)\n",
    "N = mat_X.shape[1]\n",
    "vec_w_init = np.zeros((NRow*NCol+1,1))+0.1\n",
    "exp_argument = np.matmul(vec_w_init.transpose(), mat_X) # shape = (1,N)\n",
    "y_estimate = 1.0/(1+np.exp(-np.matmul(vec_w_init.transpose(), mat_X))) # shape = (1,N)\n",
    "L = -1.0/N * np.sum(vec_y*np.log(y_estimate)+(1-vec_y)*np.log(1-y_estimate))\n",
    "\n",
    "# For the gradient of L(w) I rewrote the sum\n",
    "# We have the shapes: (y_estimate-vec_y).shape=(1, N)\n",
    "#                     mat_X.shape=(785, N)\n",
    "# The sum says, take entry i of (y_estimate-vec_y) and multiply it with vector mat_X[i]\n",
    "# which is one whole column. This is the same as mat_X * (y_estimate-vec_y).transpose() and in shapes\n",
    "# (785, N) * (N, 1) = (785,1)\n",
    "# So the summation is hidden in the matrix multiplication for each row in mat_X\n",
    "\n",
    "\n",
    "grad_L_sum = np.matmul(mat_X,(y_estimate-vec_y).transpose())\n",
    "grad_L = 1/N * grad_L_sum\n",
    "\n",
    "# The same\n",
    "grad_L_2 = 1/N * (y_estimate[0,0]-vec_y[0,0])*mat_X[:,0]\n",
    "for i in np.arange(N-1):\n",
    "    grad_L_2 += 1/N * (y_estimate[0,i+1]-vec_y[0,i+1])*mat_X[:,i+1]\n",
    "\n",
    "max_iter = 100\n",
    "step_size = 0.01\n",
    "for i in np.arange(max_iter):\n",
    "    y_estimate = 1.0/(1+np.exp(-np.matmul(vec_w_init.transpose(), mat_X))) # shape = (1,N)\n",
    "    L = -1/N * np.sum(vec_y*np.log(y_estimate)+(1-vec_y)*np.log(1-y_estimate))\n",
    "    vec_L.append(L)\n",
    "    grad_L= 1/N * np.matmul(mat_X,(y_estimate-vec_y).transpose())\n",
    "    vec_w_init = vec_w_init - step_size * grad_L\n",
    "\n",
    "\n",
    "plt.plot(vec_L)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
